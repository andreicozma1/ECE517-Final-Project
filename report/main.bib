
@article{radford2019language,
  title   = {Language models are unsupervised multitask learners},
  author  = {Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal = {OpenAI blog},
  volume  = {1},
  number  = {8},
  pages   = {9},
  year    = {2019}
}
@inproceedings{wolf2019huggingface,
  title     = {Transformers: State-of-the-Art Natural Language Processing},
  author    = {Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
  month     = oct,
  year      = {2020},
  address   = {Online},
  publisher = {Association for Computational Linguistics},
  url       = {https://www.aclweb.org/anthology/2020.emnlp-demos.6},
  pages     = {38--45}
}

@article{chen2021decision,
  title   = {Decision transformer: Reinforcement learning via sequence modeling},
  author  = {Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Misha and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
  journal = {Advances in neural information processing systems},
  volume  = {34},
  pages   = {15084--15097},
  year    = {2021}
}

@article{schulman2017proximal,
  title   = {Proximal policy optimization algorithms},
  author  = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal = {arXiv preprint arXiv:1707.06347},
  year    = {2017}
}

@article{brockman2016openai,
  title   = {Openai gym},
  author  = {Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal = {arXiv preprint arXiv:1606.01540},
  year    = {2016}
}

@book{sutton2018reinforcement,
  title     = {Reinforcement learning: An introduction},
  author    = {Sutton, Richard S and Barto, Andrew G},
  year      = {2018},
  publisher = {MIT press}
}

@misc{wandb,
  title  = {Experiment Tracking with Weights and Biases},
  year   = {2020},
  note   = {Software available from wandb.com},
  url    = {https://www.wandb.com/},
  author = {Biewald, Lukas}
}

@misc{attentionisallyouneed,
  doi       = {10.48550/ARXIV.1706.03762},
  url       = {https://arxiv.org/abs/1706.03762},
  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  keywords  = {Computation and Language (cs.CL), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {Attention Is All You Need},
  publisher = {arXiv},
  year      = {2017},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@inproceedings{mnih2016asynchronous,
  title        = {Asynchronous methods for deep reinforcement learning},
  author       = {Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle    = {International conference on machine learning},
  pages        = {1928--1937},
  year         = {2016},
  organization = {PMLR}
}
@misc{openai_2022,
  title     = {CHATGPT: Optimizing language models for dialogue},
  url       = {https://openai.com/blog/chatgpt/},
  journal   = {OpenAI},
  publisher = {OpenAI},
  author    = {OpenAI},
  year      = {2022},
  month     = {Dec}
} 

@incollection{paszke2019pytorch,
  title     = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  author    = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  booktitle = {Advances in Neural Information Processing Systems 32},
  pages     = {8024--8035},
  year      = {2019},
  publisher = {Curran Associates, Inc.},
  url       = {http://papers.neurips.cc/paper/9015-pytorch-an-imperative-style-high-performance-deep-learning-library.pdf}
}

@article{falcon2019pytorch,
  title   = {PyTorch Lightning},
  author  = {William {Falcon et al.}},
  journal = {GitHub. Note: https://github.com/PyTorchLightning/pytorch-lightning},
  volume  = {3},
  year    = {2019}
}

@misc{https://doi.org/10.48550/arxiv.1910.03771,
  doi       = {10.48550/ARXIV.1910.03771},
  url       = {https://arxiv.org/abs/1910.03771},
  author    = {Wolf, Thomas and Debut, Lysandre and Sanh, Victor and Chaumond, Julien and Delangue, Clement and Moi, Anthony and Cistac, Pierric and Rault, Tim and Louf, Rémi and Funtowicz, Morgan and Davison, Joe and Shleifer, Sam and von Platen, Patrick and Ma, Clara and Jernite, Yacine and Plu, Julien and Xu, Canwen and Scao, Teven Le and Gugger, Sylvain and Drame, Mariama and Lhoest, Quentin and Rush, Alexander M.},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {HuggingFace's Transformers: State-of-the-art Natural Language Processing},
  publisher = {arXiv},
  year      = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}
